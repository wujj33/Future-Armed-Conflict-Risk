{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "952e39ca-c1f1-4505-9aad-11bd5f8be9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7219a6e7-0084-4a10-9d01-e6210593f884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = [\n",
    "    'xcoord', 'ycoord', 'DALYs', 'min_dist', 'num', 'best', 'duration',\n",
    "    'min_dist_type1', 'num_type1', 'best_type1', 'duration_type1', 'mean_ps',\n",
    "    'unemployment', 'cisi', 'pop', 'gdp', 'gpc', 'hdi', 'cropland', 'forest',\n",
    "    'urban', 'migration', 'dem_mean', 'dem_std', 'mou_cover', 'dist2coast',\n",
    "    'ttime_mean', 'water_gc', 'ttime_sd', 'landarea', 'bdist2', 'bdist3',\n",
    "    'capdist', 'excluded', 'road_dens', 'gdmhz', 'mining', 'infant_mortality',\n",
    "    'hfp', 'ndvi', 'min_dist_geopko', 'num_geopko', 'SPI', 'hist_pre', 'STI',\n",
    "    'hist_tmp'\n",
    "]\n",
    "len(cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de73d827-283f-4f0e-8956-0ccff0d9845b",
   "metadata": {},
   "source": [
    "# hazard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b7812d-b81c-4615-a6c0-dd94e8a1d937",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = './models/models_final.pkl'\n",
    "with open(file, 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "    models = data['models']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93e2f1ca-fa87-4e49-9362-549de634c251",
   "metadata": {},
   "outputs": [],
   "source": [
    "GCMs = ['CanESM5', 'GFDL-ESM4', 'MPI-ESM1-2-LR', 'BCC-CSM2-MR', 'IPSL-CM6A-LR']\n",
    "SSPs = ['ssp126', 'ssp245', 'ssp370', 'ssp585']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc224daf-f994-4d3f-8644-411f3b8cb35a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "740"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "years = np.arange(2024, 2061)\n",
    "choices = list(product(SSPs, GCMs, years))\n",
    "num = len(choices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c53047-22e7-4268-910c-bde5c28d907e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num):\n",
    "    ssp, gcm, year = choices[i]\n",
    "    file = './all_data/%s_%s_%s.csv' % (ssp, gcm, year)\n",
    "    all_covars = pd.read_csv(file)\n",
    "    index = all_covars[cols].isna().any(axis=1)\n",
    "    all_covars = all_covars[~index].reset_index(drop=True)\n",
    "    X = all_covars[cols].values\n",
    "    hazard_cols = []\n",
    "    for k in range(20):\n",
    "        col = 'hazard_%02d' % k\n",
    "        all_covars[col] = models[k].predict_proba(X)[:, 1]\n",
    "        hazard_cols.append(col)\n",
    "    all_covars['hazard'] = all_covars[hazard_cols].mean(axis=1)\n",
    "    hazard_cols += ['gid', 'hazard']\n",
    "    file = './risk/hazard/%s_%s_%s.csv' % (gcm, ssp, year)\n",
    "    all_covars[hazard_cols].to_csv(file, index=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058bcf21-d85b-441a-b5f0-53e4f369a6d1",
   "metadata": {},
   "source": [
    "# exposure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a1f3f5e-5675-4961-8111-16fd4bc2a990",
   "metadata": {},
   "outputs": [],
   "source": [
    "SSPs = ['SSP1', 'SSP2', 'SSP3', 'SSP5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cd018f-3105-4bfd-8dc4-aafc40b7f701",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_max = 0\n",
    "pop_min = 0\n",
    "for ssp in SSPs:\n",
    "    ## pop\n",
    "    file1 = './data/WorldPop/pop_2000_2020.csv'\n",
    "    file2 = './data/SSP_POP/%s_2020_2060.csv' % (ssp)\n",
    "    df1 = pd.read_csv(file1)\n",
    "    df2 = pd.read_csv(file2)\n",
    "    df_pop = pd.merge(df1, df2, on='gid', how='left', suffixes=['', '_'])\n",
    "    cols = [str(i) for i in range(2000, 2061)]\n",
    "    if df_pop[cols].max().max() > pop_max:\n",
    "        pop_max = df_pop[cols].max().max()\n",
    "pop_max, pop_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c364dc5a-799a-4443-8619-7c0f7e14b749",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp_max = 0\n",
    "gdp_min = 0\n",
    "for ssp in SSPs:\n",
    "    ## GDP\n",
    "    file = './data/SSP_GDP/%s_2000_2060.csv' % (ssp)\n",
    "    df_gdp = pd.read_csv(file)\n",
    "    if df_gdp[cols].max().max() > gdp_max:\n",
    "        gdp_max = df_gdp[cols].max().max()\n",
    "gdp_max, gdp_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5140ed77-9b0b-4f3c-b5ec-3806b68b10e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ssp in SSPs:\n",
    "    ## pop\n",
    "    file1 = '/data/01 Datasets/19 WorldPop/pop_2000_2020.csv'\n",
    "    file2 = '/data/01 Datasets/21 SSP_POP/%s_2020_2060.csv' % (ssp)\n",
    "    df1 = pd.read_csv(file1)\n",
    "    df2 = pd.read_csv(file2)\n",
    "    df_pop = pd.merge(df1, df2, on='gid', how='left', suffixes=['', '_'])\n",
    "    cols = [str(i) for i in range(2000, 2061)]\n",
    "    ## GDP\n",
    "    file = '/data/01 Datasets/22 SSP_GDP/%s_2000_2060.csv' % (ssp)\n",
    "    df_gdp = pd.read_csv(file)\n",
    "    for col in tqdm(cols):\n",
    "        col_ = ['gid', col]\n",
    "        temp = pd.merge(df_gdp[col_],\n",
    "                        df_pop[col_],\n",
    "                        on='gid',\n",
    "                        how='left',\n",
    "                        suffixes=['_gdp', '_pop'])\n",
    "        temp['gpc'] = temp['%s_gdp' % col] / temp['%s_pop' % col]\n",
    "        index = temp['%s_pop' % col] == 0\n",
    "        temp.loc[index, 'gpc'] = 0\n",
    "        temp['gdp'] = (temp['%s_gdp' % col] - gdp_min) / (gdp_max - gdp_min)\n",
    "        temp['pop'] = (temp['%s_pop' % col] - pop_min) / (pop_max - pop_min)\n",
    "        temp['exposure'] = temp['gdp'] * 0.5 + temp['pop'] * 0.5\n",
    "        file = './risk/exposure/%s_%s.csv' % (ssp, col)\n",
    "        temp.to_csv(file, index=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa62de8-356d-406e-b2c1-2b1d2d04a4a6",
   "metadata": {},
   "source": [
    "# vulnerability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f10d439-c5fa-4d65-9d8b-4b9eef59d3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "SSPs = ['ssp126', 'ssp245', 'ssp370', 'ssp585']\n",
    "ssp_dict = {\n",
    "    'ssp126': 'SSP1',\n",
    "    'ssp245': 'SSP2',\n",
    "    'ssp370': 'SSP3',\n",
    "    'ssp585': 'SSP5'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65fba2f-61c4-43b2-9b38-06fcaf766a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdi_list = []\n",
    "gpc_list = []\n",
    "urban_list = []\n",
    "for ssp in ['ssp126', 'ssp245', 'ssp370', 'ssp585']:\n",
    "    cols = [str(i) for i in range(2000, 2061)]\n",
    "    ## HDI(-)\n",
    "    cols = [str(i) for i in range(2000, 2061)]\n",
    "    file = './data/%sHDI.csv' % ssp_dict[ssp]\n",
    "    df_hdi = pd.read_csv(file)\n",
    "    hdi_max = df_hdi[cols].max().max()\n",
    "    hdi_min = df_hdi[cols].min().min()\n",
    "    hdi_max, hdi_min\n",
    "    hdi_list.append(hdi_max)\n",
    "    hdi_list.append(hdi_min)\n",
    "    ## per capita GDP(-)\n",
    "    file = '/data/%s_GDP_PPP_per_capita.csv' % ssp_dict[ssp]\n",
    "    df_gpc = pd.read_csv(file)\n",
    "    cols = [str(i) for i in range(2000, 2061)]\n",
    "    gpc_max = df_gpc[cols].max().max()\n",
    "    gpc_min = df_gpc[cols].min().min()\n",
    "    gpc_max, gpc_min\n",
    "    gpc_list.append(gpc_max)\n",
    "    gpc_list.append(gpc_min)\n",
    "    ## urban(-)\n",
    "    cols = [str(i) for i in range(2000, 2061)]\n",
    "    file1 = './data/historical_urban.csv'\n",
    "    file2 = './data/future_urban_%s.csv' % ssp\n",
    "    df1 = pd.read_csv(file1)\n",
    "    df2 = pd.read_csv(file2)\n",
    "    df_urban = pd.merge(df1, df2, on='gid', how='left', suffixes=['', '_'])\n",
    "    urban_max = df_urban[cols].max().max()\n",
    "    urban_min = df_urban[cols].min().min()\n",
    "    urban_max, urban_min\n",
    "    urban_list.append(urban_max)\n",
    "    urban_list.append(urban_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13688a34-6e94-413e-be22-7988259e9c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdi_max = np.array(hdi_list).max()\n",
    "hdi_min = np.array(hdi_list).min()\n",
    "gpc_max = np.array(gpc_list).max()\n",
    "gpc_min = np.array(gpc_list).min()\n",
    "urban_max = np.array(urban_list).max()\n",
    "urban_min = np.array(urban_list).min()\n",
    "hdi_max, hdi_min\n",
    "gpc_max, gpc_min\n",
    "urban_max, urban_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2757d24-f4c4-4dbe-bf0c-927c199e24ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ssp in ['ssp126', 'ssp245', 'ssp370', 'ssp585']:\n",
    "    cols = [str(i) for i in range(2000, 2061)]\n",
    "    ## HDI(-)\n",
    "    cols = [str(i) for i in range(2000, 2061)]\n",
    "    file = './data/%sHDI.csv' % ssp_dict[ssp]\n",
    "    df_hdi = pd.read_csv(file)\n",
    "    df_hdi[cols] = (df_hdi[cols] - hdi_min) / (hdi_max - hdi_min)\n",
    "    df_hdi[cols] = 1 - df_hdi[cols]\n",
    "    ## per capita GDP(-)\n",
    "    file = './data/%s_GDP_PPP_per_capita.csv' % ssp_dict[ssp]\n",
    "    df_gpc = pd.read_csv(file)\n",
    "    cols = [str(i) for i in range(2000, 2061)]\n",
    "    df_gpc[cols] = (df_gpc[cols] - gpc_min) / (gpc_max - gpc_min)\n",
    "    df_gpc[cols] = 1 - df_gpc[cols]\n",
    "    ## urban(-)\n",
    "    cols = [str(i) for i in range(2000, 2061)]\n",
    "    file1 = './data/historical_urban.csv'\n",
    "    file2 = './data/future_urban_%s.csv' % ssp\n",
    "    df1 = pd.read_csv(file1)\n",
    "    df2 = pd.read_csv(file2)\n",
    "    df_urban = pd.merge(df1, df2, on='gid', how='left', suffixes=['', '_'])\n",
    "    df_urban[cols] = (df_urban[cols] - urban_min) / (urban_max - urban_min)\n",
    "    df_urban[cols] = 1 - df_urban[cols]\n",
    "    ## vulnerability\n",
    "    for year in trange(2000, 2061):\n",
    "        cols = ['gid']\n",
    "        all_covars = df_urban[cols]\n",
    "        col = str(year)\n",
    "        ##\n",
    "        temp = df_urban.rename(columns={col: 'urban'})\n",
    "        cols = ['gid', 'urban']\n",
    "        all_covars = pd.merge(all_covars,\n",
    "                              temp[cols],\n",
    "                              on='gid',\n",
    "                              suffixes=['', '_'],\n",
    "                              how='left')\n",
    "        ##\n",
    "        temp = df_hdi.rename(columns={col: 'hdi'})\n",
    "        cols = ['gid', 'hdi']\n",
    "        all_covars = pd.merge(all_covars,\n",
    "                              temp[cols],\n",
    "                              on='gid',\n",
    "                              suffixes=['', '_'],\n",
    "                              how='left')\n",
    "        ##\n",
    "        temp = df_gpc.rename(columns={col: 'gpc'})\n",
    "        cols = ['gid', 'gpc']\n",
    "        all_covars = pd.merge(all_covars,\n",
    "                              temp[cols],\n",
    "                              on='gid',\n",
    "                              suffixes=['', '_'],\n",
    "                              how='left')\n",
    "        file = './risk/vulnerability/%s_%s.csv' % (ssp, year)\n",
    "        all_covars.to_csv(file, index=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac026873-ee63-4840-af11-6a3e76b67f39",
   "metadata": {},
   "source": [
    "# risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2dd767a0-f383-4071-926d-d321d5d2d1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = np.arange(2024, 2061)\n",
    "num = len(years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9d8493b-dc08-4f9e-860b-f2be3249cd8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "740"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "choices = list(product(SSPs, GCMs, years))\n",
    "len(choices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0448a071-84fe-46ef-a2f6-2e2f4ae6d968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hazard_00',\n",
       " 'hazard_01',\n",
       " 'hazard_02',\n",
       " 'hazard_03',\n",
       " 'hazard_04',\n",
       " 'hazard_05',\n",
       " 'hazard_06',\n",
       " 'hazard_07',\n",
       " 'hazard_08',\n",
       " 'hazard_09',\n",
       " 'hazard_10',\n",
       " 'hazard_11',\n",
       " 'hazard_12',\n",
       " 'hazard_13',\n",
       " 'hazard_14',\n",
       " 'hazard_15',\n",
       " 'hazard_16',\n",
       " 'hazard_17',\n",
       " 'hazard_18',\n",
       " 'hazard_19']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hazard_cols = []\n",
    "for k in range(20):\n",
    "    col = 'hazard_%02d' % k\n",
    "    hazard_cols.append(col)\n",
    "hazard_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd1aed6-4b7a-490b-bd18-46eadb0180f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num):\n",
    "    ssp, gcm, year = choices[i]\n",
    "    ## hazard\n",
    "\n",
    "    file = './risk/hazard/%s_%s_%s.csv' % (gcm, ssp, year)\n",
    "    df_hazard = pd.read_csv(file)\n",
    "    ## exposure\n",
    "    file = './risk/exposure/%s_%s.csv' % (ssp_dict[ssp], year)\n",
    "    df_exposure = pd.read_csv(file)\n",
    "    ## vulnerability\n",
    "    file = './risk/vulnerability/%s_2000_2060.csv' % (ssp)\n",
    "    df_vulnerability = pd.read_csv(file)\n",
    "    index = df_vulnerability['year'] == year\n",
    "    df_vulnerability = df_vulnerability[index].reset_index(drop=True)\n",
    "    cols = ['gid', 'vulnerability']\n",
    "    result = study_area.merge(df_vulnerability[cols],\n",
    "                              on='gid',\n",
    "                              suffixes=['', '_'],\n",
    "                              how='left')\n",
    "    cols = ['gid', 'exposure']\n",
    "    result = result.merge(df_exposure[cols],\n",
    "                          on='gid',\n",
    "                          suffixes=['', '_'],\n",
    "                          how='left')\n",
    "    result = result.merge(df_hazard, on='gid', suffixes=['', '_'], how='left')\n",
    "    a = 0.5\n",
    "    b = 0.25\n",
    "    c = 0.25\n",
    "    final_cols = []\n",
    "    for k in range(20):\n",
    "        col = '%s_%02d' % (gcm, k)\n",
    "        result[col] = (result['hazard_%02d' % k]**a) * (\n",
    "            result['exposure']**b) * (result['vulnerability']**c)\n",
    "        final_cols.append(col)\n",
    "    result['risk_std'] = result[final_cols].std(axis=1)\n",
    "    result['risk_%s' % gcm] = result[final_cols].mean(axis=1)\n",
    "    result['risk_all_%s' %\n",
    "           gcm] = (result['hazard']**a) * (result['exposure']**\n",
    "                                           b) * (result['vulnerability']**c)\n",
    "    result['risk_he_%s' % gcm] = (result['hazard']**a) * (result['exposure']**b)\n",
    "    result['risk_hv_%s' %\n",
    "           gcm] = (result['hazard']**a) * (result['vulnerability']**c)\n",
    "    result['risk_ev_%s' %\n",
    "           gcm] = (result['exposure']**b) * (result['vulnerability']**c)\n",
    "    final_cols = [\n",
    "        'gid', 'region', 'country', 'exposure', 'vulnerability', 'hazard'\n",
    "    ] + hazard_cols + final_cols + [\n",
    "        'risk_all_%s' % gcm,\n",
    "        'risk_%s' % gcm, 'risk_std',\n",
    "        'risk_he_%s' % gcm,\n",
    "        'risk_hv_%s' % gcm,\n",
    "        'risk_ev_%s' % gcm\n",
    "    ]\n",
    "    file = './risk/%s_%s_%s.csv' % (ssp, gcm, year)\n",
    "    result[final_cols].to_csv(file, index=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
